\addsec*{Abstract}
\label{sct:abstract}
Convolutional Neural Networks (CNNs) are widely used in image classification and other domains. They are multi-layered architectures resembling neurons in the human visual information processing system. These CNNs are computationally expensive to implement and hence the need for special hardware to improve inference time arises. Hardware accelerators such as FPGAs have shown great promise in terms of performance with several benefits such as increased parallelism and their highly re-configurable nature when compared with GPU, CPU or ASIC.  In this project, our primary goal was to deploy a few state-of-the-art CNN topologies on multiple Intel Stratix 10 FPGAs to investigate their performance, identify bottlenecks and carry out optimizations. In particular, we deployed two CNNs (namely GoogLeNet Inception V1 and ResNet-50) by using a combination of two machine learning frameworks (namely TVM and Intel OpenVINO) on the ImageNet dataset. TVM was used for OpenCL code generation of these large CNN topologies and OpenVINO for running the generated code on FPGAs. To make these two frameworks work together, we modified the TVM generated kernels to match OpenVINO’s intermediate representation and we also developed an FPGA plugin which is a part of OpenVINO’s inference engine and has all the necessary data structures and functions required to perform inference and return the output with results. Along with these results, we used OpenCL’s profiler reports to analyze bottlenecks and perform necessary optimizations on our code.


\textit{\textbf{Keywords}: Image Classification, CNN, FPGA, OpenCL, TVM, OpenVINO}